{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ba80a9",
   "metadata": {},
   "source": [
    "# Data Mining - Brain-to-text '25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3484a",
   "metadata": {},
   "source": [
    "## Overview of the competition\n",
    "\n",
    "People with ALS or brainstem stroke can lose the ability to move and speak. Speech brain-computer interfaces (BCIs) can restore communication by decoding what someone is trying to say directly from their brain activity. Once decoded, the person’s intended message can be spoken for them or typed as text on a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad331a3e",
   "metadata": {},
   "source": [
    "### Loading hdf5 file in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e327045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGIT_PHONE_DEF = [\n",
    "    'BLANK', 'SIL', # blank and silence\n",
    "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "    'AY', 'B',  'CH', 'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'JH', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'OY', 'P', 'R', 'S', 'SH',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z', 'ZH'\n",
    "]\n",
    "SIL_DEF = ['SIL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the data from the hdf5 file\n",
    "def load_h5py_file(file_path):\n",
    "    data = {\n",
    "        'neural_features': [],\n",
    "        'n_time_steps': [],\n",
    "        'seq_class_ids': [],\n",
    "        'seq_len': [],\n",
    "        'transcriptions': [],\n",
    "        'sentence_label': [],\n",
    "        'session': [],\n",
    "        'block_num': [],\n",
    "        'trial_num': [],\n",
    "    }\n",
    "    # Open the hdf5 file for that day\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "\n",
    "        keys = list(f.keys())\n",
    "\n",
    "        # For each trial in the selected trials in that day\n",
    "        for key in keys:\n",
    "            g = f[key]\n",
    "\n",
    "            neural_features = g['input_features'][:]\n",
    "            n_time_steps = g.attrs['n_time_steps']\n",
    "            seq_class_ids = g['seq_class_ids'][:] if 'seq_class_ids' in g else None\n",
    "            seq_len = g.attrs['seq_len'] if 'seq_len' in g.attrs else None\n",
    "            transcription = g['transcription'][:] if 'transcription' in g else None\n",
    "            sentence_label = g.attrs['sentence_label'][:] if 'sentence_label' in g.attrs else None\n",
    "            session = g.attrs['session']\n",
    "            block_num = g.attrs['block_num']\n",
    "            trial_num = g.attrs['trial_num']\n",
    "\n",
    "            data['neural_features'].append(neural_features)\n",
    "            data['n_time_steps'].append(n_time_steps)\n",
    "            data['seq_class_ids'].append(seq_class_ids)\n",
    "            data['seq_len'].append(seq_len)\n",
    "            data['transcriptions'].append(transcription)\n",
    "            data['sentence_label'].append(sentence_label)\n",
    "            data['session'].append(session)\n",
    "            data['block_num'].append(block_num)\n",
    "            data['trial_num'].append(trial_num)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/t15_copyTask_neuralData/hdf5_data_final'\n",
    "\n",
    "# Recursively search for all *train.hdf5 files under all subdirectories of DATA_PATH\n",
    "def get_data_files(data_type='train'):\n",
    "    \"\"\"\n",
    "    Return a list of files matching the given data type ('train', 'val', or 'test').\n",
    "    \"\"\"\n",
    "    return glob.glob(os.path.join(DATA_PATH, '**', f'*{data_type}.hdf5'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = get_data_files('train')\n",
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data into a single DataFrame\n",
    "def load_data(files):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in tqdm(files, desc=\"Loading data\"):\n",
    "        data = load_h5py_file(file)\n",
    "        df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a89d32",
   "metadata": {},
   "source": [
    "## Data observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4799ae",
   "metadata": {},
   "source": [
    "### Understand the Structure & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ecbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ab8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57983cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicate sentence_label data\n",
    "duplicate_count = sum(train_df.duplicated(subset=['sentence_label']))\n",
    "print(f\"Duplicate sentence_label count: {duplicate_count}\")\n",
    "\n",
    "# Count duplicate sentence_label data ratio\n",
    "duplicate_ratio = train_df.duplicated(subset=['sentence_label']).mean() * 100\n",
    "print(f\"Duplicate sentence_label ratio: {duplicate_ratio:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display duplicated sentence_label data\n",
    "duplicated_sentences = train_df[train_df.duplicated(subset=['sentence_label'], keep=False)].sort_values(by=['sentence_label', 'session'])\n",
    "duplicated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the n_time_steps differences for duplicated sentence_label (interactive plot)\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Find duplicated sentence_labels\n",
    "dup_sent_labels = train_df[train_df.duplicated(subset=['sentence_label'], keep=False)]['sentence_label'].unique()\n",
    "\n",
    "# Keep only rows with these duplicated sentence_labels\n",
    "dup_df = train_df[train_df['sentence_label'].isin(dup_sent_labels)].copy()\n",
    "\n",
    "# Prepare long-format data\n",
    "plot_df = dup_df[['sentence_label', 'n_time_steps']].copy()\n",
    "plot_df['Occurrence'] = plot_df.groupby('sentence_label').cumcount() + 1\n",
    "\n",
    "# Interactive line plot: one line per duplicated sentence\n",
    "fig = go.Figure()\n",
    "for label in dup_sent_labels:\n",
    "    group = plot_df[plot_df['sentence_label'] == label]\n",
    "    if len(group) > 1:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=group['Occurrence'],\n",
    "            y=group['n_time_steps'],\n",
    "            mode='lines+markers',\n",
    "            name=label,\n",
    "            text=[label]*len(group),\n",
    "            opacity=0.5,\n",
    "            hovertemplate='sentence: %{text}<br>Occurrence: %{x}<br>n_time_steps: %{y}<extra></extra>'\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"n_time_steps differences for duplicated sentence_label (interactive)\",\n",
    "    xaxis_title=\"Occurrence (different trials of the same sentence)\",\n",
    "    yaxis_title=\"n_time_steps\",\n",
    "    legend_title=\"sentence_label\",\n",
    "    height=600,\n",
    "    width=1200\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive boxplot\n",
    "box_data = plot_df.groupby('sentence_label').filter(lambda x: len(x) > 1)\n",
    "fig2 = px.box(\n",
    "    box_data,\n",
    "    x='sentence_label',\n",
    "    y='n_time_steps',\n",
    "    title=\"Distribution of n_time_steps for duplicated sentence_label (interactive boxplot)\",\n",
    "    labels={'sentence_label': 'sentence_label', 'n_time_steps': 'n_time_steps'}\n",
    ")\n",
    "fig2.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    height=600,\n",
    "    width=1300\n",
    ")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the neural features data\n",
    "for i in range(5):\n",
    "    print(f\"Shape of data item {i}: \")\n",
    "    print(f\"\\t neural_features {np.array(train_df['neural_features'][i]).shape}\")\n",
    "    print(f\"\\t seq_class_ids len {np.array(train_df['seq_len'][i])}\")\n",
    "    # 忽略 0 並計算長度\n",
    "    transcriptions = np.array(train_df['transcriptions'][i])\n",
    "    transcriptions_wo_zero = transcriptions[transcriptions != 0]\n",
    "    print(f\"\\t transcriptions len (ignore 0): {len(transcriptions_wo_zero)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ba76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "trl = randint(0, len(train_df))  # 可以改成你想看的 trial 編號\n",
    "\n",
    "features = np.array(train_df['neural_features'][trl])  # shape: (time, channel)\n",
    "\n",
    "# 顯示該 trial 的基本資訊\n",
    "print(f\"session:      {train_df['session'][trl]}\")\n",
    "print(f\"block_num:    {train_df['block_num'][trl]}\")\n",
    "print(f\"trial_num:    {train_df['trial_num'][trl]}\")\n",
    "print(f\"sentence:     {train_df['sentence_label'][trl]}\")\n",
    "\n",
    "# 畫出所有 channel 的 heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(features.T, aspect='auto', cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Neural Activity')\n",
    "plt.ylabel('Channel')\n",
    "plt.xlabel('Time')\n",
    "plt.title(f\" Neural Features Heatmap\\nSession: {train_df['session'][trl]}, Trial: {trl}, sentence: \\\"{train_df['sentence_label'][trl]}\\\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_steps = np.array(train_df['n_time_steps'])\n",
    "plt.hist(n_time_steps, bins=50)\n",
    "plt.title(\"Distribution of time steps per trial\")\n",
    "plt.xlabel(\"Number of time steps\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b69900",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = np.array(train_df['seq_len'])\n",
    "plt.hist(seq_len, bins=50)\n",
    "plt.title(\"Distribution of sequence lengths per trial\")\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(train_df[['n_time_steps', 'seq_len']], alpha=0.5, figsize=(10, 8), diagonal='kde')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3edaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of class ids\n",
    "# Concatenate all seq_class_ids from all trials into a single list\n",
    "all_class_ids = []\n",
    "for seq in train_df['seq_class_ids']:\n",
    "    all_class_ids.extend(seq)\n",
    "all_class_ids = np.array(all_class_ids)\n",
    "\n",
    "# Count the frequency of each class id\n",
    "min_id = int(all_class_ids.min())\n",
    "max_id = int(all_class_ids.max())\n",
    "class_ids = np.arange(min_id, max_id + 1)\n",
    "counts = np.array([(all_class_ids == cid).sum() for cid in class_ids])\n",
    "\n",
    "# Take log on y-axis\n",
    "log_counts = np.log10(counts + 1)  # Add 1 to avoid log(0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=class_ids,\n",
    "    y=log_counts,\n",
    "    text=counts,  # Show actual frequency\n",
    "    textposition='outside',\n",
    "    marker_color='skyblue'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Class ID Frequency Distribution (log scale, all trials)',\n",
    "    xaxis_title='Class ID',\n",
    "    yaxis_title='log10(Frequency + 1)',\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=class_ids,\n",
    "        ticktext=[str(cid) for cid in class_ids]\n",
    "    ),\n",
    "    bargap=0.1,\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly use all_class_ids to map to phonemes, ensuring the distribution matches class id distribution\n",
    "def ids_to_phonemes(seq_ids, id2symbol):\n",
    "    return [id2symbol[i] if 0 <= i < len(id2symbol) else f\"UNK_{i}\" for i in seq_ids]\n",
    "\n",
    "# Get all phoneme labels corresponding to class ids\n",
    "all_phoneme_labels = np.array(ids_to_phonemes(all_class_ids, LOGIT_PHONE_DEF))\n",
    "\n",
    "# Count the frequency of each class id (corresponds to class_ids, counts above)\n",
    "min_id = int(all_class_ids.min())\n",
    "max_id = int(all_class_ids.max())\n",
    "class_ids = np.arange(min_id, max_id + 1)\n",
    "phoneme_list = [LOGIT_PHONE_DEF[cid] if 0 <= cid < len(LOGIT_PHONE_DEF) else f\"UNK_{cid}\" for cid in class_ids]\n",
    "counts = np.array([(all_class_ids == cid).sum() for cid in class_ids])\n",
    "\n",
    "# Take log on y-axis\n",
    "log_counts = np.log10(counts + 1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=phoneme_list,\n",
    "    y=log_counts,\n",
    "    text=counts,  # Show actual frequency\n",
    "    textposition='outside',\n",
    "    marker_color='skyblue'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Phoneme Frequency Distribution (log scale, all trials)',\n",
    "    xaxis_title='Phoneme',\n",
    "    yaxis_title='log10(Frequency + 1)',\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=phoneme_list,\n",
    "        ticktext=phoneme_list\n",
    "    ),\n",
    "    bargap=0.1,\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all time points from all trials into a single (total_time_points, channel) matrix\n",
    "all_features_matrix = np.concatenate(train_df['neural_features'], axis=0)  # shape: (total_time, channel)\n",
    "all_features_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 50000\n",
    "idx = np.random.choice(all_features_matrix.shape[0], sample_n, replace=False)\n",
    "all_features_matrix_sample = all_features_matrix[idx, :]\n",
    "\n",
    "all_features_matrix_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c669d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use min-max range color bar + mean line for a cleaner distribution visualization\n",
    "means = np.mean(all_features_matrix_sample, axis=0)      # (channel,)\n",
    "mins = np.min(all_features_matrix_sample, axis=0)        # (channel,)\n",
    "maxs = np.max(all_features_matrix_sample, axis=0)        # (channel,)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "channels = np.arange(all_features_matrix_sample.shape[1])\n",
    "\n",
    "# Plot min-max range as a color bar\n",
    "plt.fill_between(channels, mins, maxs, color='skyblue', alpha=0.5, label='min-max range')\n",
    "\n",
    "# Plot mean line\n",
    "plt.plot(channels, means, color='navy', linewidth=2, label='mean')\n",
    "\n",
    "plt.title(\"Signal distribution per neural feature (min-max + mean)\")\n",
    "plt.xlabel(\"Feature index (0–511)\")\n",
    "plt.ylabel(\"Neural activity\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(all_features_matrix_sample.T)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(corr, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Feature correlation map')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on (channel, time) to analyze the distribution across channels\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='randomized')\n",
    "pca_result = pca.fit_transform(all_features_matrix_sample)  # shape: (channel, 2)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(pca_result[:,0], pca_result[:,1], s=2, alpha=0.5)\n",
    "plt.title('PCA of All Channel-Time Points)')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69173b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每個 channel 在主成分上的貢獻\n",
    "\n",
    "loadings = pca.components_\n",
    "\n",
    "print(loadings.shape)\n",
    "\n",
    "top_pca1 = np.argsort(np.abs(loadings[0, :]))[-10:]\n",
    "top_pca2 = np.argsort(np.abs(loadings[1, :]))[-10:]\n",
    "\n",
    "print(\"PCA 1 最重要的前 10 個 channel：\")\n",
    "for rank, idx in enumerate(top_pca1, 1):\n",
    "    print(f\"  {rank}. channel {idx}，貢獻 {loadings[0, idx]:.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"PCA 2 最重要的前 10 個 channel：\")\n",
    "for rank, idx in enumerate(top_pca2, 1):\n",
    "    print(f\"  {rank}. channel {idx}，貢獻 {loadings[1, idx]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "best_n_clusters = 0\n",
    "best_score = -1\n",
    "best_labels = None\n",
    "n = 2\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "labels = kmeans.fit_predict(all_features_matrix_sample)\n",
    "score = silhouette_score(all_features_matrix_sample, labels)\n",
    "print(f\"n_clusters={n}，Silhouette Score={score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(pca_result[:,0], pca_result[:,1], c=labels, cmap='viridis', s=2, alpha=0.5)\n",
    "plt.title('KMeans Clustering of All Channel-Time Points)')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
